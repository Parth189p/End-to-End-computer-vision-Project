{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lapto\\\\OneDrive\\\\Desktop\\\\Face-reg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataprocessConfig:\n",
    "    root_dir: Path\n",
    "    preprocessed_dir: Path\n",
    "    data: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Facerecognition.constants import *\n",
    "from src.Facerecognition.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_processing_config(self) -> DataprocessConfig:\n",
    "        config = self.config.data_preprocessing\n",
    "        data = os.path.join(self.config.data_ingestion.unzip_dir, \"Facerecognition\")\n",
    "        create_directories([Path(config.root_dir)])\n",
    "        \n",
    "        data_preprocess_config = DataprocessConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            preprocessed_dir=config.preprocessed_dir,\n",
    "            data = Path(data)\n",
    "        )\n",
    "\n",
    "        return data_preprocess_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "import zipfile\n",
    "from src.Facerecognition import logger\n",
    "from src.Facerecognition.utils.common import  get_size\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    def __init__(self, config: DataprocessConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def preprocess_data(self, data_preprocess_config):\n",
    "        image_width = 224\n",
    "        image_height = 224\n",
    "        cascade_file_path = os.path.abspath('haarcascade_frontalface_default.xml')\n",
    "        facecascade = cv2.CascadeClassifier(cascade_file_path)\n",
    "        images_dir = data_preprocess_config.data\n",
    "\n",
    "        # Create a new directory for preprocessed images within the root directory\n",
    "        preprocessed_images_dir = data_preprocess_config.root_dir / \"preprocessed_images\"\n",
    "        preprocessed_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        current_id = 0\n",
    "        label_ids = {}\n",
    "\n",
    "        for root, _, files in os.walk(images_dir):\n",
    "            for file in files:\n",
    "                if file.endswith((\"png\", \"jpg\", \"jpeg\")):\n",
    "                    # Path of the image\n",
    "                    path = os.path.join(root, file)\n",
    "\n",
    "                    # Get the label name (name of the person)\n",
    "                    label = os.path.basename(root).replace(\" \", \".\").lower()\n",
    "\n",
    "                    # Create a subdirectory for each class (label)\n",
    "                    class_dir = preprocessed_images_dir / label\n",
    "                    class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    # Load the image\n",
    "                    imgtest = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "                    image_array = np.array(imgtest, \"uint8\")\n",
    "\n",
    "                    # Get the faces detected in the image\n",
    "                    faces = facecascade.detectMultiScale(imgtest, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "                    # If not exactly 1 face is detected, skip this photo\n",
    "                    if len(faces) != 1:\n",
    "                        print(f'---Photo skipped---\\n')\n",
    "                        continue\n",
    "\n",
    "                    # Save the detected face(s) in the class subdirectory\n",
    "                    for (x_, y_, w, h) in faces:\n",
    "                        # Resize the detected face to 224x224\n",
    "                        size = (image_width, image_height)\n",
    "\n",
    "                        # Detected face region\n",
    "                        roi = image_array[y_: y_ + h, x_: x_ + w]\n",
    "\n",
    "                        # Resize the detected head to the target size\n",
    "                        resized_image = cv2.resize(roi, size)\n",
    "\n",
    "                        preprocessed_image_path = class_dir / f\"{current_id}.jpg\"\n",
    "                        im = Image.fromarray(resized_image)\n",
    "                        im.save(preprocessed_image_path)\n",
    "                        current_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataPreprocess:\n",
    "#     def __init__(self, config: DataprocessConfig):\n",
    "#         self.config = config\n",
    "\n",
    "#     def preprocess_data(self, data_preprocess_config):\n",
    "#         image_width = 224\n",
    "#         image_height = 224\n",
    "#         cascade_file_path = os.path.abspath('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#         facecascade = cv2.CascadeClassifier(cascade_file_path)\n",
    "#         images_dir = data_preprocess_config.data\n",
    "\n",
    "#         # Create a new directory for preprocessed images within the root directory\n",
    "#         preprocessed_images_dir = data_preprocess_config.root_dir / \"preprocessed_images\"\n",
    "#         preprocessed_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         current_id = 0\n",
    "#         label_ids = {}\n",
    "\n",
    "#         for root, _, files in os.walk(images_dir):\n",
    "#             for file in files:\n",
    "#                 if file.endswith((\"png\", \"jpg\", \"jpeg\")):\n",
    "#                     # Path of the image\n",
    "#                     path = os.path.join(root, file)\n",
    "\n",
    "#                     # Get the label name (name of the person)\n",
    "#                     label = os.path.basename(root).replace(\" \", \".\").lower()\n",
    "\n",
    "#                     # Add the label (key) and its number (value)\n",
    "#                     if label not in label_ids:\n",
    "#                         label_ids[label] = current_id\n",
    "#                         current_id += 1\n",
    "\n",
    "#                     # Load the image\n",
    "#                     imgtest = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "#                     image_array = np.array(imgtest, \"uint8\")\n",
    "\n",
    "#                     # Get the faces detected in the image\n",
    "#                     faces = facecascade.detectMultiScale(imgtest, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "#                     # If not exactly 1 face is detected, skip this photo\n",
    "#                     if len(faces) != 1:\n",
    "#                         print(f'---Photo skipped---\\n')\n",
    "#                         continue\n",
    "\n",
    "#                     # Save the detected face(s) and associate them with the label\n",
    "#                     for (x_, y_, w, h) in faces:\n",
    "#                         # Resize the detected face to 224x224\n",
    "#                         size = (image_width, image_height)\n",
    "\n",
    "#                         # Detected face region\n",
    "#                         roi = image_array[y_: y_ + h, x_: x_ + w]\n",
    "\n",
    "#                         # Resize the detected head to the target size\n",
    "#                         resized_image = cv2.resize(roi, size)\n",
    "\n",
    "#                         preprocessed_image_path = preprocessed_images_dir / f\"{current_id}.jpg\"\n",
    "#                         im = Image.fromarray(resized_image)\n",
    "#                         im.save(preprocessed_image_path)\n",
    "#                         current_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 11:14:01,420: INFO: common yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-10-13 11:14:01,423: INFO: common yaml file: params.yaml loaded successfully]\n",
      "[2023-10-13 11:14:01,426: INFO: common created directory at: artifacts]\n",
      "[2023-10-13 11:14:01,426: INFO: common created directory at: artifacts\\data_preprocessing]\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n",
      "---Photo skipped---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_preprocess_config = config.get_data_processing_config()\n",
    "    data_preprocess = DataPreprocess(config=data_preprocess_config)\n",
    "    data_preprocess.preprocess_data(data_preprocess_config)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
